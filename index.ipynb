{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensions to Linear Models - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab, you'll practice many concepts learned in this section, from adding interactions and polynomials to your model to AIC and BIC!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You will be able to:\n",
    "- Build a linear regression model with polynomial features/interactions\n",
    "- Perform regularization\n",
    "- Use AIC and BIC to select the best value for the regularization parameter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at a Baseline Boston Housing Data Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Boston housing data set, use all the predictors in their scaled version (using `preprocessing.scale`. Look at a baseline model using *scaled variables* as predictors. Use 5-fold cross-validation this time and use the $R^2$ score to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7176324491383005"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "regression = LinearRegression()\n",
    "boston = load_boston()\n",
    "y = pd.DataFrame(boston.target,columns = [\"target\"])\n",
    "df = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "\n",
    "X_scaled = preprocessing.scale(df)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns = df.columns)\n",
    "\n",
    "all_data = pd.concat([y,X_scaled], axis = 1)\n",
    "\n",
    "crossvalidation = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "baseline = np.mean(cross_val_score(regression, X_scaled, y, scoring=\"r2\", cv=crossvalidation))\n",
    "baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X_scaled=preprocessing.scale(X)\\nX_train, X_test, y_train, y_test = train_test_split (X_scaled,y, test_size=0.3, random_state=12 )\\n\\nreg=LinearRegression().fit(X_train, y_train)\\n\\n\\n\\nfrom sklearn.model_selection import cross_val_score\\n\\nbaseline = cross_val_score(reg, X_train, y_train,  cv=5)\\nprint(\"R_square = \" , np.mean(scores))'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"X_scaled=preprocessing.scale(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split (X_scaled,y, test_size=0.3, random_state=12 )\n",
    "\n",
    "reg=LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "baseline = cross_val_score(reg, X_train, y_train,  cv=5)\n",
    "print(\"R_square = \" , np.mean(scores))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include interactions\n",
    "\n",
    "Look at all the possible combinations of variables for interactions by adding interactions one by one to the baseline model. Next, evaluate that model using 5-fold classification and store the $R^2$ to compare it with the baseline model.\n",
    "\n",
    "You've created code for this before in the interactions lab, yet this time, you have scaled the variables so the outcomes may look different. \n",
    "\n",
    "Print the 7 most important interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 7 interactions: [('RM', 'LSTAT', 0.783), ('RM', 'TAX', 0.775), ('RM', 'RAD', 0.77), ('RM', 'PTRATIO', 0.764), ('INDUS', 'RM', 0.757), ('NOX', 'RM', 0.746), ('RM', 'AGE', 0.742)]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from itertools import combinations\n",
    "combinations = list(combinations(boston.feature_names, 2))\n",
    "\n",
    "interactions = []\n",
    "data = X_scaled.copy()\n",
    "for comb in combinations:\n",
    "    data[\"interaction\"] = data[comb[0]] * data[comb[1]]\n",
    "    score = np.mean(cross_val_score(regression, data, y, scoring=\"r2\", cv=crossvalidation))\n",
    "    if score > baseline: interactions.append((comb[0], comb[1], round(score,3)))\n",
    "            \n",
    "print(\"Top 7 interactions: %s\" %sorted(interactions, key=lambda inter: inter[2], reverse=True)[:7])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to include the 7 most important interactions in your data set by adding 7 columns. Name the columns \"var1_var2\" with var1 and var2 the two variables in the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>RM_LSTAT</th>\n",
       "      <th>RM_TAX</th>\n",
       "      <th>RM_RAD</th>\n",
       "      <th>RM_PTRATIO</th>\n",
       "      <th>INDUS_RM</th>\n",
       "      <th>NOX_RM</th>\n",
       "      <th>RM_AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.417713</td>\n",
       "      <td>0.284830</td>\n",
       "      <td>-1.287909</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>0.413672</td>\n",
       "      <td>-0.120013</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>-0.982843</td>\n",
       "      <td>-0.666608</td>\n",
       "      <td>-1.459000</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.075562</td>\n",
       "      <td>32.74350</td>\n",
       "      <td>1946.200</td>\n",
       "      <td>6.575</td>\n",
       "      <td>100.5975</td>\n",
       "      <td>15.18825</td>\n",
       "      <td>3.537350</td>\n",
       "      <td>428.6900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.415269</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>0.194274</td>\n",
       "      <td>0.367166</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-0.492439</td>\n",
       "      <td>58.68794</td>\n",
       "      <td>1553.882</td>\n",
       "      <td>12.842</td>\n",
       "      <td>114.2938</td>\n",
       "      <td>45.39647</td>\n",
       "      <td>3.011449</td>\n",
       "      <td>506.6169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.415272</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-0.593381</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.740262</td>\n",
       "      <td>1.282714</td>\n",
       "      <td>-0.265812</td>\n",
       "      <td>0.557160</td>\n",
       "      <td>-0.867883</td>\n",
       "      <td>-0.987329</td>\n",
       "      <td>-0.303094</td>\n",
       "      <td>0.396427</td>\n",
       "      <td>-1.208727</td>\n",
       "      <td>28.95555</td>\n",
       "      <td>1738.770</td>\n",
       "      <td>14.370</td>\n",
       "      <td>127.8930</td>\n",
       "      <td>50.79795</td>\n",
       "      <td>3.369765</td>\n",
       "      <td>439.0035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.414680</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.016303</td>\n",
       "      <td>-0.809889</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.416163</td>\n",
       "      <td>-1.361517</td>\n",
       "      <td>20.57412</td>\n",
       "      <td>1553.556</td>\n",
       "      <td>20.994</td>\n",
       "      <td>130.8626</td>\n",
       "      <td>15.25564</td>\n",
       "      <td>3.205084</td>\n",
       "      <td>320.5084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.410409</td>\n",
       "      <td>-0.487722</td>\n",
       "      <td>-1.306878</td>\n",
       "      <td>-0.272599</td>\n",
       "      <td>-0.835284</td>\n",
       "      <td>1.228577</td>\n",
       "      <td>-0.511180</td>\n",
       "      <td>1.077737</td>\n",
       "      <td>-0.752922</td>\n",
       "      <td>-1.106115</td>\n",
       "      <td>0.113032</td>\n",
       "      <td>0.441052</td>\n",
       "      <td>-1.026501</td>\n",
       "      <td>38.09351</td>\n",
       "      <td>1586.634</td>\n",
       "      <td>21.441</td>\n",
       "      <td>133.6489</td>\n",
       "      <td>15.58046</td>\n",
       "      <td>3.273326</td>\n",
       "      <td>387.3674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0 -0.417713  0.284830 -1.287909 -0.272599 -0.144217  0.413672 -0.120013   \n",
       "1 -0.415269 -0.487722 -0.593381 -0.272599 -0.740262  0.194274  0.367166   \n",
       "2 -0.415272 -0.487722 -0.593381 -0.272599 -0.740262  1.282714 -0.265812   \n",
       "3 -0.414680 -0.487722 -1.306878 -0.272599 -0.835284  1.016303 -0.809889   \n",
       "4 -0.410409 -0.487722 -1.306878 -0.272599 -0.835284  1.228577 -0.511180   \n",
       "\n",
       "        DIS       RAD       TAX   PTRATIO         B     LSTAT  RM_LSTAT  \\\n",
       "0  0.140214 -0.982843 -0.666608 -1.459000  0.441052 -1.075562  32.74350   \n",
       "1  0.557160 -0.867883 -0.987329 -0.303094  0.441052 -0.492439  58.68794   \n",
       "2  0.557160 -0.867883 -0.987329 -0.303094  0.396427 -1.208727  28.95555   \n",
       "3  1.077737 -0.752922 -1.106115  0.113032  0.416163 -1.361517  20.57412   \n",
       "4  1.077737 -0.752922 -1.106115  0.113032  0.441052 -1.026501  38.09351   \n",
       "\n",
       "     RM_TAX  RM_RAD  RM_PTRATIO  INDUS_RM    NOX_RM    RM_AGE  \n",
       "0  1946.200   6.575    100.5975  15.18825  3.537350  428.6900  \n",
       "1  1553.882  12.842    114.2938  45.39647  3.011449  506.6169  \n",
       "2  1738.770  14.370    127.8930  50.79795  3.369765  439.0035  \n",
       "3  1553.556  20.994    130.8626  15.25564  3.205084  320.5084  \n",
       "4  1586.634  21.441    133.6489  15.58046  3.273326  387.3674  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "df_inter = X_scaled.copy()\n",
    "ls_interactions = sorted(interactions, key=lambda inter: inter[2], reverse=True)[:7]\n",
    "for inter in ls_interactions:\n",
    "    df_inter[inter[0]+\"_\"+inter[1]] =df[inter[0]]*df[inter[1]]\n",
    "    \n",
    "    \n",
    "df_inter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include Polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try polynomials of 2, 3 and 4 for each variable, in a similar way you did for interactions (by looking at your baseline model and seeing how $R^2$ increases). Do understand that when going for a polynomial of 4, the particular column is raised to the power of 2 and 3 as well in other terms. We only want to include \"pure\" polynomials, so make sure no interactions are included. We want the result to return a list that contain tuples of the form:\n",
    "\n",
    "`(var_name, degree, R2)`, so eg. `('DIS', 3, 0.732)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 polynomials: [('RM', 4, 0.8), ('RM', 2, 0.782), ('LSTAT', 4, 0.782), ('RM', 3, 0.781), ('LSTAT', 3, 0.774), ('LSTAT', 2, 0.772), ('DIS', 3, 0.737), ('DIS', 2, 0.732), ('DIS', 4, 0.731), ('TAX', 4, 0.724)]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "polynomials = []\n",
    "for col in df.columns:\n",
    "    for degree in [2,3,4]:\n",
    "        data = X_scaled.copy()\n",
    "        poly = PolynomialFeatures(degree, include_bias=False)\n",
    "        X = poly.fit_transform(df[[col]])\n",
    "        data = pd.concat([data.drop(col, axis=1),pd.DataFrame(X)], axis = 1)\n",
    "        score = np.mean(cross_val_score(regression, data, y, scoring=\"r2\", cv=crossvalidation))\n",
    "        if score > baseline: polynomials.append((col, degree, round(score,3)))\n",
    "print(\"Top 10 polynomials: %s\" %sorted(polynomials, key=lambda poly: poly[2], reverse=True)[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each variable, print out the maximum R2 possible when including Polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "ZN         0.723\n",
       "INDUS      0.723\n",
       "NOX        0.721\n",
       "RM         0.800\n",
       "AGE        0.722\n",
       "DIS        0.737\n",
       "RAD        0.719\n",
       "TAX        0.724\n",
       "PTRATIO    0.721\n",
       "B          0.720\n",
       "LSTAT      0.782\n",
       "Name: 2, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "polies=pd.DataFrame(polynomials)\n",
    "polies.groupby([0], sort=False)[2].max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which two variables seem to benefit most from adding Polynomial terms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Polynomials for the two features that seem to benefit the most, as in have the best R squared compared to the baseline model. For each of the two feature, raise to the Polynomial that generates the best result. Make sure to start from the data set `df_inter` so the final data set has both interactions and polynomials in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "for col in [\"RM\", \"LSTAT\"]:\n",
    "    poly = PolynomialFeatures(4, include_bias=False)\n",
    "    X = poly.fit_transform(df[[col]])\n",
    "    colnames= [col, col+\"_\"+\"2\", col+\"_\"+\"3\", col+\"_\"+\"4\"]\n",
    "    df_inter = pd.concat([df_inter.drop(col, axis=1),pd.DataFrame(X, columns=colnames)], axis = 1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check out your final data set and make sure that your interaction terms as well as your polynomial terms are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'AGE', 'DIS', 'RAD', 'TAX',\n",
       "       'PTRATIO', 'B', 'RM_LSTAT', 'RM_TAX', 'RM_RAD', 'RM_PTRATIO',\n",
       "       'INDUS_RM', 'NOX_RM', 'RM_AGE', 'RM', 'RM_2', 'RM_3', 'RM_4', 'LSTAT',\n",
       "       'LSTAT_2', 'LSTAT_3', 'LSTAT_4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "df_inter.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full model R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the R-squared of the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8061116489236815"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "score = np.mean(cross_val_score(regression, df_inter, y, scoring=\"r2\", cv=crossvalidation))\n",
    "score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best Lasso regularization parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've learned that, when using Lasso regularization, your coefficients shrink to 0 when using a higher regularization parameter. Now the question is which value we should choose for the regularization parameter. \n",
    "\n",
    "This is where the AIC and BIC come in handy! We'll use both criteria in what follows and perform cross-validation to select an optimal value of the regularization parameter alpha of the Lasso estimator.\n",
    "\n",
    "Read the page here: https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html and create a similar plot as the first one listed on the page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8014160844784429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.30102221e+00,  4.14249517e-02,  1.11540429e+00,\n",
       "         5.86841407e-01, -6.93295474e-01,  9.09761943e-01,\n",
       "        -1.79342393e+00,  1.28813644e+00,  1.22905993e+00,\n",
       "         3.28233635e+00,  6.00985159e-01, -5.97652457e-02,\n",
       "        -3.00002877e-03,  1.76126105e-02, -3.54433029e-01,\n",
       "        -1.56018137e-02, -1.26495280e+00, -4.13658340e-03,\n",
       "         1.01514996e-01, -2.36728519e-01,  2.22573009e-01,\n",
       "        -1.12716001e-02, -2.82602956e+00,  2.17126313e-01,\n",
       "        -7.42228379e-03,  9.11220107e-05]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code her \n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "ridgereg=Ridge(alpha=4).fit(df_inter, y)\n",
    "\n",
    "score = np.mean(cross_val_score(ridgereg, df_inter, y, scoring=\"r2\", cv=crossvalidation))\n",
    "print(score)\n",
    "\n",
    "ridgereg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.766114892372798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -1.58839006e-01,\n",
       "       -1.75161766e-03,  1.91191562e-02, -8.19049456e-02,  8.77996599e-03,\n",
       "       -0.00000000e+00,  2.80842082e-03, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  6.53610486e-03, -0.00000000e+00, -0.00000000e+00,\n",
       "        5.40258369e-04, -8.58410993e-06])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lassoreg=Lasso(alpha=3).fit(df_inter, y)\n",
    "\n",
    "score = np.mean(cross_val_score(lassoreg, df_inter, y, scoring=\"r2\", cv=crossvalidation))\n",
    "print(score)\n",
    "\n",
    "lassoreg.coef_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04606644293310453\n",
      "[506.         504.77235836 414.7677569  369.22482001 200.48978219\n",
      " 154.56500442 159.59477441 163.01020132 163.83472177 166.71223087\n",
      " 169.81671665 170.42015914 176.08824164 170.01549254 175.93704217\n",
      " 181.57419155 182.80286211 182.57580581 174.80602147 173.16884276\n",
      " 179.23141269 184.61416995 184.40406943 182.96376089 182.84127057\n",
      " 182.69676779 188.74713364 194.28937653 193.99700412 192.4922918\n",
      " 198.36696515 197.25107572 197.25054591 203.47311123 209.44477352\n",
      " 215.43791624 215.25105011 215.17218464 221.3826054  227.50985834\n",
      " 227.22948778 220.34320001 220.2126054  219.79287129 219.50101874\n",
      " 225.64215982 231.86736637 231.70773378 231.59500669 229.33611081\n",
      " 229.07649496 234.92110398 234.80143274 228.46040526 228.45031321\n",
      " 234.65678652 234.03506965 233.98121123 240.17768843]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LassoCV, LassoLarsCV, LassoLarsIC   \n",
    "model_bic = LassoLarsIC(criterion='bic')  #create instance and define the model parameter. if it is bic it is bic model\n",
    "model_bic.fit(df_inter, y)\n",
    "alpha_bic_ = model_bic.alpha_    #it picks the feature that generates lowest aic bic\n",
    "print( alpha_bic_) \n",
    "print(model_bic.criterion_)\n",
    "model_aic = LassoLarsIC(criterion='aic') #it the parameter aic , you can get the aic model\n",
    "model_aic.fit(df_inter, y)\n",
    "alpha_aic_ = model_aic.alpha_ \n",
    "\n",
    "\n",
    "def plot_ic_criterion(model, name, color):\n",
    "    alpha_ = model.alpha_\n",
    "    alphas_ = model.alphas_\n",
    "    criterion_ = model.criterion_\n",
    "    \n",
    "    plt.plot(-np.log10(alphas_), criterion_, '--', color=color, linewidth=2, label= name)\n",
    "    plt.axvline(-np.log10(alpha_), color=color, linewidth=2,\n",
    "                label='alpha for %s ' % name)\n",
    "    plt.xlabel('-log(alpha)')\n",
    "    plt.ylabel('criterion')\n",
    "\n",
    "plt.figure()\n",
    "plot_ic_criterion(model_aic, 'AIC', 'green')\n",
    "plot_ic_criterion(model_bic, 'BIC', 'blue')\n",
    "plt.legend()\n",
    "plt.title('Information-criterion for model selection');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing feature selection: comparing models with only a few variables and more variables, computing the AIC/BIC and select the features that generated the lowest AIC or BIC\n",
    "Similarly, selecting or not selecting interactions/polynomial features depending on whether or not the AIC/BIC decreases when adding them in\n",
    "Computing the AIC and BIC for several values of the regularization parameter in Ridge/Lasso models and selecting the best regularization parameter.\n",
    "Many more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the final result\n",
    "\n",
    "Finally, use the best value for regularization parameter according to AIC and BIC and compare the R squared parameters and MSE using train-test-split. Compare with the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_model(model,X_train,X_test,y_train,y_test):\n",
    "    \n",
    "    print('Training R^2 :',model.score(X_train,y_train))\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    print('Training Root Mean Square Error',np.sqrt(mean_squared_error(y_train,y_pred_train)))\n",
    "    print('\\n----------------\\n')\n",
    "    print('Testing R^2 :',model.score(X_test,y_test))\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    print('Testing Root Mean Square Error',np.sqrt(mean_squared_error(y_test,y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R^2 : 0.8493217973015355\n",
      "Training Root Mean Square Error 3.529954308378633\n",
      "\n",
      "----------------\n",
      "\n",
      "Testing R^2 : 0.7938646490796002\n",
      "Testing Root Mean Square Error 4.252501989343672\n"
     ]
    }
   ],
   "source": [
    "# Code for baseline model\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split (df_inter, y, test_size=0.3, random_state=12 )\n",
    "\n",
    "reg=LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "run_model(reg, X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R^2 : 0.8368717098146593\n",
      "Training Root Mean Square Error 3.672894977979949\n",
      "\n",
      "----------------\n",
      "\n",
      "Testing R^2 : 0.7604839569477487\n",
      "Testing Root Mean Square Error 4.583904817070087\n"
     ]
    }
   ],
   "source": [
    "# code for lasso with alpha from AIC\n",
    "\n",
    "lassoreg=Lasso(alpha=alpha_bic_).fit(X_train, y_train)\n",
    "run_model(lassoreg, X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training R^2 : 0.8421253250957326\n",
      "Training Root Mean Square Error 3.6132674015998463\n",
      "\n",
      "----------------\n",
      "\n",
      "Testing R^2 : 0.7674145345745379\n",
      "Testing Root Mean Square Error 4.5170986234869135\n"
     ]
    }
   ],
   "source": [
    "# code for lasso with alpha from BIC\n",
    "lassoreg=Lasso(alpha=alpha_aic_).fit(X_train, y_train)\n",
    "run_model(lassoreg, X_train,X_test,y_train,y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up - Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Lasso Path\n",
    "\n",
    "From this section, you know that when using lasso, more parameters shrink to zero as your regularization parameter goes up. In Scikit-Learn there is a function lasso_path which visualizes the shrinkage of the coefficients while alpha changes. Try this out yourself!\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_coordinate_descent_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIC and BIC for subset selection\n",
    "This notebook shows how you can use AIC and BIC purely for feature selection. Try this code out on our Boston Housing data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://xavierbourretsicotte.github.io/subset_selection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now know how to create better linear models and how to use AIC and BIC for both feature selection and to optimize your regularization parameter when performing Ridge and Lasso. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
